[
    {
        "function_name": "string_slice_next",
        "file_name": "E:\\rust_projects\\c\\delta-kernel-rs\\ffi\\examples\\read-table\\read_table.c",
        "commit_count": 0,
        "commits": []
    },
    {
        "function_name": "string_slice_next",
        "file_name": "E:\\rust_projects\\c\\delta-kernel-rs\\ffi\\src\\lib.rs",
        "commit_count": 1,
        "commits": [
            {
                "commit_info": "43b2f256ff47cd7494196d1cf3257aaa73d1be83",
                "commit_title": "Have an ffi c example that actually reads data (#203)\n\nFlesh out what a more full FFI API for data reading would look like. We\ncan certainly iterate on this.\n\nLots more into the example for using the c-ffi (sorry for another big\nPR. It's mostly example code at least):\n\n- Actually read the data\n- Include partition columns\n- Print out the table\n- Use `clang-format` to get consistent c style\n- Add _all_ the gcc warnings, make them errors, and fix them\n\nUnfortunately the glib arrow api doesn't seem to allow passing options\nto how we print things, so this will print a max of 4 rows out the\ntable. To print more we'd need to write our own printing function.\n\nThis also adds `engine_funcs.rs` which currently only exposes\n`read_parquet_files`. This is more of a POC, but seems like potentially\nthe right way forward for exposing the various functions available to\nrust when it has an `Engine`.\n\nA couple of example runs:\n\nReading the `basic_partitioned` table:\n```\nReading table at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/basic_partitioned/delta/\nversion: 1\n\nBuilding schema\nMaking a list of lenth 3 with id 0\nAsked to visit string named letter belonging to list 0.\nAsked to visit long named number belonging to list 0.\nAsked to visit double named a_float belonging to list 0.\nSchema returned in list 0\nDone building schema\nSchema:\n\u251c\u2500 letter: string\n\u251c\u2500 number: long\n\u2514\u2500 a_float: double\n\nStarting table scan\n\nBuilding list of partition columns\nDone iterating partition columns\nPartition columns are:\n  - letter\n\nIterating scan data\n\nScan iterator found some data to read\n  Of this data, here is a selection vector\n    sel[0] = 0\n    sel[1] = 1\n    sel[2] = 1\n    sel[3] = 1\nAsking kernel to call us back for each scan row (file to read)\nCalled back to read file: letter=a/part-00000-b17b8597-4c08-4867-b882-2249d604cbc2.c000.snappy.parquet\n  No selection vector for this file\n  partition 'letter' here: a\n  Reading parquet file at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/basic_partitioned/delta/letter=a/part-00000-b17b8597-4c08-4867-b882-2249d604cbc2.c000.snappy.parquet\n  Converting read data to arrow\n  Adding partition column 'letter' with value 'a' at column 2\n  Added batch to arrow context, have 1 batches in context now\n  Done reading parquet file\nCalled back to read file: letter=e/part-00000-90f8c03f-e005-4714-a8ac-55bcf6d94d7d.c000.snappy.parquet\n  No selection vector for this file\n  partition 'letter' here: e\n  Reading parquet file at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/basic_partitioned/delta/letter=e/part-00000-90f8c03f-e005-4714-a8ac-55bcf6d94d7d.c000.snappy.parquet\n  Converting read data to arrow\n  Adding partition column 'letter' with value 'e' at column 2\n  Added batch to arrow context, have 2 batches in context now\n  Done reading parquet file\nCalled back to read file: letter=f/part-00000-4da5e756-3c84-4b40-b483-ebcf3c4ed6ce.c000.snappy.parquet\n  No selection vector for this file\n  partition 'letter' here: f\n  Reading parquet file at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/basic_partitioned/delta/letter=f/part-00000-4da5e756-3c84-4b40-b483-ebcf3c4ed6ce.c000.snappy.parquet\n  Converting read data to arrow\n  Adding partition column 'letter' with value 'f' at column 2\n  Added batch to arrow context, have 3 batches in context now\n  Done reading parquet file\n\nScan iterator found some data to read\n  Of this data, here is a selection vector\n    sel[0] = 0\n    sel[1] = 0\n    sel[2] = 0\n    sel[3] = 1\n    sel[4] = 1\n    sel[5] = 1\nAsking kernel to call us back for each scan row (file to read)\nCalled back to read file: letter=a/part-00000-8fe836ee-ec38-4388-91a1-5c3eff176e84.c000.snappy.parquet\n  No selection vector for this file\n  partition 'letter' here: a\n  Reading parquet file at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/basic_partitioned/delta/letter=a/part-00000-8fe836ee-ec38-4388-91a1-5c3eff176e84.c000.snappy.parquet\n  Converting read data to arrow\n  Adding partition column 'letter' with value 'a' at column 2\n  Added batch to arrow context, have 4 batches in context now\n  Done reading parquet file\nCalled back to read file: letter=b/part-00000-2465ef7c-268e-43be-98fe-c9c37a2a6482.c000.snappy.parquet\n  No selection vector for this file\n  partition 'letter' here: b\n  Reading parquet file at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/basic_partitioned/delta/letter=b/part-00000-2465ef7c-268e-43be-98fe-c9c37a2a6482.c000.snappy.parquet\n  Converting read data to arrow\n  Adding partition column 'letter' with value 'b' at column 2\n  Added batch to arrow context, have 5 batches in context now\n  Done reading parquet file\nCalled back to read file: letter=c/part-00000-28c8b160-ee9c-407d-93f5-ff7d8e2a8d3f.c000.snappy.parquet\n  No selection vector for this file\n  partition 'letter' here: c\n  Reading parquet file at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/basic_partitioned/delta/letter=c/part-00000-28c8b160-ee9c-407d-93f5-ff7d8e2a8d3f.c000.snappy.parquet\n  Converting read data to arrow\n  Adding partition column 'letter' with value 'c' at column 2\n  Added batch to arrow context, have 6 batches in context now\n  Done reading parquet file\nScan data iterator done\nAll done reading table data\n\nTable Data:\n-----------\n\nnumber: int64\na_float: double\nletter: string\n----\nnumber:\n  [\n    [\n      4\n    ],\n    [\n      5\n    ],\n  ...,\n    [\n      2\n    ],\n    [\n      3\n    ]\n  ]\na_float:\n  [\n    [\n      4.4\n    ],\n    [\n      5.5\n    ],\n  ...,\n    [\n      2.2\n    ],\n    [\n      3.3\n    ]\n  ]\nletter:\n  [\n    [\n      \"a\"\n    ],\n    [\n      \"e\"\n    ],\n  ...,\n    [\n      \"b\"\n    ],\n    [\n      \"c\"\n    ]\n  ]\n```\n\nReading the `nested_types` table\n```\nReading table at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/nested_types/delta/\nversion: 0\n\nBuilding schema\nMaking a list of lenth 4 with id 0\nAsked to visit integer named pk belonging to list 0.\nMaking a list of lenth 2 with id 1\nAsked to visit double named float64 belonging to list 1.\nAsked to visit boolean named bool belonging to list 1.\nAsked to visit struct named struct belonging to list 0. Children are in 1.\nMaking a list of lenth 1 with id 2\nAsked to visit short named array_element belonging to list 2.\nAsked to visit array named array (contains null: true) belonging to list 0. Types are in 2.\nMaking a list of lenth 2 with id 3\nAsked to visit string named map_key belonging to list 3.\nAsked to visit integer named map_value belonging to list 3.\nAsked to visit map named map (contains null: true) belonging to list 0. Types are in 3.\nSchema returned in list 0\nDone building schema\nSchema:\n\u251c\u2500 pk: integer\n\u251c\u2500 struct: struct\n\u2502  \u251c\u2500 float64: double\n\u2502  \u2514\u2500 bool: boolean\n\u251c\u2500 array (contains null: true): array\n\u2502  \u2514\u2500 array_element: short\n\u2514\u2500 map (contains null: true): map\n   \u251c\u2500 map_key: string\n   \u2514\u2500 map_value: integer\n\nStarting table scan\n\nBuilding list of partition columns\nDone iterating partition columns\nTable has no partition columns\n\nIterating scan data\n\nScan iterator found some data to read\n  Of this data, here is a selection vector\n    sel[0] = 0\n    sel[1] = 0\n    sel[2] = 0\n    sel[3] = 1\nAsking kernel to call us back for each scan row (file to read)\nCalled back to read file: part-00000-3b8ca3f0-6444-4ed5-8961-c605cba95bf1-c000.snappy.parquet\n  No selection vector for this file\n  Reading parquet file at file:///home/nick/databricks/delta-kernel-rs/acceptance/tests/dat/out/reader_tests/generated/nested_types/delta/part-00000-3b8ca3f0-6444-4ed5-8961-c605cba95bf1-c000.snappy.parquet\n  Converting read data to arrow\n  Added batch to arrow context, have 1 batches in context now\n  Done reading parquet file\nScan data iterator done\nAll done reading table data\n\nTable Data:\n-----------\n\npk: int32\nstruct: struct<float64: double, bool: bool>\n  child 0, float64: double\n  child 1, bool: bool\narray: list<element: int16>\n  child 0, element: int16\nmap: map<string, int32>\n  child 0, entries: struct<key: string not null, value: int32> not null\n      child 0, key: string not null\n      child 1, value: int32\n----\npk:\n  [\n    [\n      0,\n      1,\n      2,\n      3,\n      4\n    ]\n  ]\nstruct:\n  [\n    -- is_valid: all not null\n    -- child 0 type: double\n      [\n        0,\n        1,\n        2,\n        3,\n        4\n      ]\n    -- child 1 type: bool\n      [\n        true,\n        false,\n        true,\n        false,\n        true\n      ]\n  ]\narray:\n  [\n    [\n      [\n        0\n      ],\n      [\n        0,\n        1\n      ],\n      [\n        0,\n        1,\n        2\n      ],\n      [\n        0,\n        1,\n        2,\n        3\n      ],\n      [\n        0,\n        1,\n        2,\n        3,\n        4\n      ]\n    ]\n  ]\nmap:\n  [\n    [\n      keys:\n      []\n      values:\n      [],\n      keys:\n      [\n        \"0\"\n      ]\n      values:\n      [\n        0\n      ],\n      keys:\n      [\n        \"0\",\n        \"1\"\n      ]\n      values:\n      [\n        0,\n        1\n      ],\n      keys:\n      [\n        \"0\",\n        \"1\",\n        \"2\"\n      ]\n      values:\n      [\n        0,\n        1,\n        2\n      ],\n      keys:\n      [\n        \"0\",\n        \"1\",\n        \"2\",\n        \"3\"\n      ]\n      values:\n      [\n        0,\n        1,\n        2,\n        3\n      ]\n    ]\n  ]\n```",
                "commit_date": "Mon Jul 1 11:14:53 2024 -0700",
                "added_functions": [
                    "pub unsafe extern \"C\" fn string_slice_next(\n    data: Handle<StringSliceIterator>,\n    engine_context: NullableCvoid,\n    engine_visitor: extern \"C\" fn(engine_context: NullableCvoid, slice: KernelStringSlice),\n) -> bool {"
                ]
            }
        ]
    }
]